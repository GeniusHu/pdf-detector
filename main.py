#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PDFç›¸ä¼¼åºåˆ—æ£€æµ‹ä¸»ç¨‹åº
ç”¨äºæ£€æµ‹ä¸¤ä¸ªPDFæ–‡ä»¶ä¸­çš„ç›¸ä¼¼åºåˆ—
"""

import sys
import os
import time
import argparse
from pathlib import Path

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from duplicate_detector import DuplicateDetector
from optimized_duplicate_detector import OptimizedSimilarSequenceDetector, fast_similarity_detection
from enhanced_pdf_extractor import EnhancedPDFTextExtractor, TextExtractionConfig, create_default_main_content_extractor


def check_pdf_files(pdf1_path: str, pdf2_path: str) -> bool:
    """
    æ£€æŸ¥PDFæ–‡ä»¶æ˜¯å¦å­˜åœ¨å’Œå¯è¯»

    Args:
        pdf1_path: ç¬¬ä¸€ä¸ªPDFæ–‡ä»¶è·¯å¾„
        pdf2_path: ç¬¬äºŒä¸ªPDFæ–‡ä»¶è·¯å¾„

    Returns:
        bool: æ–‡ä»¶æ£€æŸ¥æ˜¯å¦é€šè¿‡
    """
    # æ£€æŸ¥æ–‡ä»¶1
    if not os.path.exists(pdf1_path):
        print(f"é”™è¯¯: æ–‡ä»¶1ä¸å­˜åœ¨: {pdf1_path}")
        return False

    if not os.path.isfile(pdf1_path):
        print(f"é”™è¯¯: æ–‡ä»¶1ä¸æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶: {pdf1_path}")
        return False

    if not pdf1_path.lower().endswith('.pdf'):
        print(f"è­¦å‘Š: æ–‡ä»¶1å¯èƒ½ä¸æ˜¯PDFæ–‡ä»¶: {pdf1_path}")

    # æ£€æŸ¥æ–‡ä»¶2
    if not os.path.exists(pdf2_path):
        print(f"é”™è¯¯: æ–‡ä»¶2ä¸å­˜åœ¨: {pdf2_path}")
        return False

    if not os.path.isfile(pdf2_path):
        print(f"é”™è¯¯: æ–‡ä»¶2ä¸æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶: {pdf2_path}")
        return False

    if not pdf2_path.lower().endswith('.pdf'):
        print(f"è­¦å‘Š: æ–‡ä»¶2å¯èƒ½ä¸æ˜¯PDFæ–‡ä»¶: {pdf2_path}")

    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    size1 = os.path.getsize(pdf1_path)
    size2 = os.path.getsize(pdf2_path)

    print(f"æ–‡ä»¶1: {pdf1_path} ({size1 / 1024 / 1024:.1f} MB)")
    print(f"æ–‡ä»¶2: {pdf2_path} ({size2 / 1024 / 1024:.1f} MB)")

    if size1 == 0 or size2 == 0:
        print("é”™è¯¯: å…¶ä¸­ä¸€ä¸ªæ–‡ä»¶ä¸ºç©º")
        return False

    return True


def get_output_filename(pdf1_path: str, pdf2_path: str) -> str:
    """
    ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å

    Args:
        pdf1_path: ç¬¬ä¸€ä¸ªPDFæ–‡ä»¶è·¯å¾„
        pdf2_path: ç¬¬äºŒä¸ªPDFæ–‡ä»¶è·¯å¾„

    Returns:
        str: è¾“å‡ºæ–‡ä»¶å
    """
    # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
    name1 = Path(pdf1_path).stem
    name2 = Path(pdf2_path).stem

    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    output_filename = f"duplicate_{name1}_{name2}_results.txt"

    # ç¡®ä¿æ–‡ä»¶åä¸ä¼šå¤ªé•¿
    if len(output_filename) > 100:
        output_filename = f"duplicate_results_{int(time.time())}.txt"

    return output_filename


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="æ£€æµ‹ä¸¤ä¸ªPDFæ–‡ä»¶ä¸­çš„ç›¸ä¼¼åºåˆ—",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python main.py file1.pdf file2.pdf
  python main.py file1.pdf file2.pdf --no-save
  python main.py file1.pdf file2.pdf --similarity 0.8
  python main.py file1.pdf file2.pdf --output custom_results.txt

å¿«é€Ÿæ¨¡å¼ï¼ˆæ¨èç”¨äºå¤§æ–‡ä»¶ï¼‰:
  python main.py file1.pdf file2.pdf --fast
  python main.py file1.pdf file2.pdf --fast --similarity 0.9
  python main.py file1.pdf file2.pdf --ultra-fast
  python main.py file1.pdf file2.pdf --fast --processes 8 --max-sequences 3000

æ³¨æ„:
  - æ£€æµ‹8å­—è¿ç»­åºåˆ—çš„ç›¸ä¼¼åº¦ï¼ˆé»˜è®¤â‰¥0.75ï¼‰
  - æ”¯æŒå¤§æ–‡ä»¶å¤„ç†ï¼ˆ20ä¸‡å­—ä»¥ä¸Šï¼‰
  - æ ‡å‡†æ¨¡å¼å¯èƒ½è¾ƒæ…¢ï¼Œå»ºè®®ä½¿ç”¨ --fast é€‰é¡¹
  - å¿«é€Ÿæ¨¡å¼ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†ï¼Œå¤§å¹…æå‡é€Ÿåº¦
  - è¶…å¿«æ¨¡å¼æ›´ä¸¥æ ¼ä½†é€Ÿåº¦æœ€å¿«
  - ç›¸ä¼¼åº¦èŒƒå›´ï¼š0.0-1.0ï¼Œè¶Šé«˜è¶Šç›¸ä¼¼
        """
    )

    parser.add_argument('pdf1', help='ç¬¬ä¸€ä¸ªPDFæ–‡ä»¶è·¯å¾„')
    parser.add_argument('pdf2', help='ç¬¬äºŒä¸ªPDFæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--no-save', action='store_true', help='ä¸ä¿å­˜ç»“æœåˆ°æ–‡ä»¶')
    parser.add_argument('--output', '-o', help='æŒ‡å®šè¾“å‡ºæ–‡ä»¶å')
    parser.add_argument('--similarity', '-s', type=float, default=0.75,
                       help='ç›¸ä¼¼åº¦é˜ˆå€¼ (0.0-1.0ï¼Œé»˜è®¤0.75)')
    parser.add_argument('--exact', action='store_true', help='åªæ£€æµ‹å®Œå…¨åŒ¹é…ï¼ˆä¸ä½¿ç”¨ç›¸ä¼¼åº¦ï¼‰')

    # ä¼˜åŒ–ç›¸å…³é€‰é¡¹
    parser.add_argument('--fast', '-f', action='store_true', help='ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼ˆå¤šè¿›ç¨‹+æ™ºèƒ½ä¼˜åŒ–ï¼‰')
    parser.add_argument('--processes', '-p', type=int, default=None,
                       help='å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤è‡ªåŠ¨æ£€æµ‹ï¼‰')
    parser.add_argument('--max-sequences', '-m', type=int, default=5000,
                       help='æ¯ä¸ªæ–‡ä»¶çš„æœ€å¤§åºåˆ—æ•°ï¼ˆé»˜è®¤5000ï¼Œç”¨äºæ§åˆ¶æ€§èƒ½ï¼‰')
    parser.add_argument('--ultra-fast', action='store_true', help='è¶…å¿«æ¨¡å¼ï¼ˆæ›´ä¸¥æ ¼çš„é™åˆ¶ï¼‰')

    # å†…å®¹è¿‡æ»¤é€‰é¡¹
    parser.add_argument('--main-content-only', action='store_true', default=True,
                       help='åªå¯¹æ¯”æ­£æ–‡å†…å®¹ï¼Œè¿‡æ»¤å¼•ç”¨ã€æ‰¹æ³¨ã€é¡µçœ‰é¡µè„šç­‰ï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    parser.add_argument('--include-references', action='store_true',
                       help='åŒ…å«å‚è€ƒæ–‡çŒ®')
    parser.add_argument('--include-citations', action='store_true',
                       help='åŒ…å«å¼•æ–‡å¼•ç”¨')
    parser.add_argument('--include-footnotes', action='store_true',
                       help='åŒ…å«è„šæ³¨')
    parser.add_argument('--include-headers', action='store_true',
                       help='åŒ…å«é¡µçœ‰é¡µè„š')
    parser.add_argument('--min-line-length', type=int, default=10,
                       help='æœ€å°è¡Œé•¿åº¦ï¼ˆé»˜è®¤10å­—ç¬¦ï¼Œè¿‡æ»¤çŸ­è¡Œï¼‰')
    parser.add_argument('--sequence-length', type=int, default=8,
                       help='åºåˆ—é•¿åº¦ï¼ˆé»˜è®¤8å­—ç¬¦ï¼Œå¯è®¾ä¸º4-20ï¼‰')

    # é¡µç èŒƒå›´é€‰é¡¹
    parser.add_argument('--page-range1', type=str, default=None,
                       help='æ–‡ä»¶1çš„é¡µç èŒƒå›´ï¼Œæ ¼å¼: 1-146 (åªæ¯”å¯¹1-146é¡µ)')
    parser.add_argument('--page-range2', type=str, default=None,
                       help='æ–‡ä»¶2çš„é¡µç èŒƒå›´ï¼Œæ ¼å¼: 1-169 (åªæ¯”å¯¹1-169é¡µ)')

    parser.add_argument('--version', action='version', version='PDFç›¸ä¼¼åºåˆ—æ£€æµ‹å™¨ v2.1')

    args = parser.parse_args()

    # éªŒè¯ç›¸ä¼¼åº¦é˜ˆå€¼
    if not 0.0 <= args.similarity <= 1.0:
        print("é”™è¯¯: ç›¸ä¼¼åº¦é˜ˆå€¼å¿…é¡»åœ¨0.0-1.0ä¹‹é—´")
        sys.exit(1)

    # å¤„ç†ä¼˜åŒ–æ¨¡å¼å‚æ•°
    max_sequences = args.max_sequences
    similarity_threshold = args.similarity

    if args.ultra_fast:
        print("âš¡ è¶…å¿«æ¨¡å¼å¯ç”¨")
        similarity_threshold = 0.9  # æ›´ä¸¥æ ¼çš„ç›¸ä¼¼åº¦
        # åªæœ‰ç”¨æˆ·æ²¡æŒ‡å®šmax_sequencesæ—¶æ‰è¦†ç›–
        if max_sequences == 5000:  # é»˜è®¤å€¼
            max_sequences = 2000
        print(f"é…ç½®: ç›¸ä¼¼åº¦â‰¥{similarity_threshold}, æœ€å¤§åºåˆ—æ•°={max_sequences}")

    elif args.fast:
        print("ğŸš€ å¿«é€Ÿæ¨¡å¼å¯ç”¨")
        similarity_threshold = 0.8  # æ›´ä¸¥æ ¼çš„ç›¸ä¼¼åº¦
        # åªæœ‰ç”¨æˆ·æ²¡æŒ‡å®šmax_sequencesæ—¶æ‰è¦†ç›–
        if max_sequences == 5000:  # é»˜è®¤å€¼
            max_sequences = 5000
        print(f"é…ç½®: ç›¸ä¼¼åº¦â‰¥{similarity_threshold}, æœ€å¤§åºåˆ—æ•°={max_sequences}")

    # è§£æé¡µç èŒƒå›´
    def parse_page_range(range_str: str):
        """è§£æé¡µç èŒƒå›´å­—ç¬¦ä¸²ï¼Œå¦‚ '1-146' -> (1, 146)"""
        if not range_str:
            return None
        try:
            parts = range_str.split('-')
            if len(parts) == 2:
                return (int(parts[0]), int(parts[1]))
        except:
            pass
        return None

    page_range1 = parse_page_range(args.page_range1)
    page_range2 = parse_page_range(args.page_range2)

    # åˆ›å»ºå†…å®¹è¿‡æ»¤é…ç½®ï¼ˆä¸¤ä¸ªæ–‡ä»¶åˆ†åˆ«é…ç½®ï¼‰
    content_config1 = TextExtractionConfig(
        include_references=args.include_references,
        include_footnotes=args.include_footnotes,
        include_citations=args.include_citations,
        include_page_numbers=args.include_headers,
        include_headers_footers=args.include_headers,
        include_annotations=False,
        min_line_length=args.min_line_length,
        remove_duplicate_lines=True,
        page_range=page_range1
    )

    content_config2 = TextExtractionConfig(
        include_references=args.include_references,
        include_footnotes=args.include_footnotes,
        include_citations=args.include_citations,
        include_page_numbers=args.include_headers,
        include_headers_footers=args.include_headers,
        include_annotations=False,
        min_line_length=args.min_line_length,
        remove_duplicate_lines=True,
        page_range=page_range2
    )

    # ä½¿ç”¨ä¸€ä¸ªé€šç”¨çš„é…ç½®ç”¨äºæ˜¾ç¤º
    content_config = content_config1

    # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
    print("=" * 80)
    print("PDFç›¸ä¼¼åºåˆ—æ£€æµ‹å™¨ v2.1 - æ­£æ–‡å†…å®¹å¯¹æ¯”ç‰ˆ")
    print("=" * 80)

    seq_len = args.sequence_length
    if args.exact:
        print(f"åŠŸèƒ½: æ£€æµ‹ä¸¤ä¸ªPDFæ–‡ä»¶ä¸­å®Œå…¨ç›¸åŒçš„{seq_len}å­—åºåˆ—")
    elif args.ultra_fast:
        print(f"åŠŸèƒ½: è¶…å¿«æ¨¡å¼æ£€æµ‹ç›¸ä¼¼åº¦â‰¥{similarity_threshold:.2f}çš„{seq_len}å­—åºåˆ—")
    elif args.fast:
        print(f"åŠŸèƒ½: å¿«é€Ÿæ¨¡å¼æ£€æµ‹ç›¸ä¼¼åº¦â‰¥{similarity_threshold:.2f}çš„{seq_len}å­—åºåˆ—")
    else:
        print(f"åŠŸèƒ½: æ£€æµ‹ä¸¤ä¸ªPDFæ–‡ä»¶ä¸­ç›¸ä¼¼åº¦â‰¥{args.similarity:.2f}çš„{seq_len}å­—åºåˆ—")

    print("è§„åˆ™: è¿‡æ»¤æ ‡ç‚¹ç¬¦å·ï¼Œè‹±æ–‡å•è¯ç®—ä¸€ä¸ªå­—ï¼Œä¸­æ–‡é€å­—è®¡ç®—ï¼Œæ•°å­—æ•´ä½“ç®—ä¸€ä¸ªå­—")
    print("è¾“å‡º: ç›¸ä¼¼åºåˆ—åŠåœ¨ä¸¤ä¸ªæ–‡ä»¶ä¸­çš„ä½ç½®ä¿¡æ¯å’Œå·®å¼‚è¯´æ˜")

    # æ˜¾ç¤ºå†…å®¹è¿‡æ»¤è®¾ç½®
    print("\nğŸ“„ å†…å®¹è¿‡æ»¤è®¾ç½®:")
    if args.main_content_only:
        print("âœ… åªå¯¹æ¯”æ­£æ–‡å†…å®¹ï¼ˆè¿‡æ»¤: å¼•ç”¨ã€æ‰¹æ³¨ã€é¡µçœ‰é¡µè„šç­‰ï¼‰")
    else:
        print("âš ï¸  åŒ…å«æ‰€æœ‰å†…å®¹ï¼ˆå¯èƒ½å½±å“æ£€æµ‹ç²¾åº¦ï¼‰")

    if args.include_references:
        print("âœ… åŒ…å«å‚è€ƒæ–‡çŒ®")
    if args.include_citations:
        print("âœ… åŒ…å«å¼•æ–‡å¼•ç”¨")
    if args.include_footnotes:
        print("âœ… åŒ…å«è„šæ³¨")
    if args.include_headers:
        print("âœ… åŒ…å«é¡µçœ‰é¡µè„š")

    print(f"ğŸ“ æœ€å°è¡Œé•¿åº¦: {args.min_line_length} å­—ç¬¦")

    if args.fast or args.ultra_fast:
        print(f"\nğŸš€ æ€§èƒ½ä¼˜åŒ–:")
        print(f"   å¤šè¿›ç¨‹å¤„ç† (è¿›ç¨‹æ•°: {args.processes or 'è‡ªåŠ¨'})")
        print(f"   æ¯æ–‡ä»¶æœ€å¤š{max_sequences:,}ä¸ªåºåˆ—")

    print("=" * 80)

    # æ£€æŸ¥æ–‡ä»¶
    if not check_pdf_files(args.pdf1, args.pdf2):
        print("\næ–‡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„")
        sys.exit(1)

    try:
        # è¿è¡Œæ£€æµ‹
        if args.fast or args.ultra_fast:
            # ä½¿ç”¨ä¼˜åŒ–ç‰ˆæ£€æµ‹å™¨
            print(f"\nğŸš€ ä½¿ç”¨ä¼˜åŒ–ç‰ˆæ£€æµ‹å™¨ï¼ˆæ­£æ–‡å†…å®¹å¯¹æ¯”ï¼‰...")
            print(f"ğŸ“ åºåˆ—é•¿åº¦: {args.sequence_length} å­—ç¬¦")
            optimized_detector = OptimizedSimilarSequenceDetector(
                args.pdf1, args.pdf2, similarity_threshold, args.processes, max_sequences, args.sequence_length
            )

            # è®¾ç½®å†…å®¹è¿‡æ»¤é…ç½®
            if args.main_content_only:
                # ä½¿ç”¨å¢å¼ºç‰ˆPDFæå–å™¨
                enhanced_extractor1 = EnhancedPDFTextExtractor(content_config1, args.pdf1)
                enhanced_extractor2 = EnhancedPDFTextExtractor(content_config2, args.pdf2)

                # æ›¿æ¢æ£€æµ‹å™¨ä¸­çš„æå–å™¨
                optimized_detector.extractor1 = enhanced_extractor1
                optimized_detector.extractor2 = enhanced_extractor2
                print("âœ… å·²å¯ç”¨æ­£æ–‡å†…å®¹è¿‡æ»¤")

            print(f"ğŸ“ å†…å®¹æå–é…ç½®:")
            print(f"   å‚è€ƒæ–‡çŒ®: {'åŒ…å«' if content_config.include_references else 'è¿‡æ»¤'}")
            print(f"   å¼•æ–‡å¼•ç”¨: {'åŒ…å«' if content_config.include_citations else 'è¿‡æ»¤'}")
            print(f"   é¡µçœ‰é¡µè„š: {'åŒ…å«' if content_config.include_headers_footers else 'è¿‡æ»¤'}")
            print(f"   æœ€å°è¡Œé•¿åº¦: {content_config.min_line_length} å­—ç¬¦")

            # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
            if not args.no_save:
                if args.output:
                    output_file = args.output
                else:
                    if args.ultra_fast:
                        output_file = get_output_filename(args.pdf1, args.pdf2).replace("duplicate_", "ultra_fast_")
                    else:
                        output_file = get_output_filename(args.pdf1, args.pdf2).replace("duplicate_", "fast_")

                # ä¿®æ”¹æ£€æµ‹å™¨çš„ä¿å­˜æ–¹æ³•
                original_save_method = optimized_detector.save_results_optimized
                def save_with_custom_filename(similar_sequences, filename=output_file):
                    original_save_method(similar_sequences, filename)
                optimized_detector.save_results_optimized = save_with_custom_filename

            # è¿è¡Œä¼˜åŒ–ç‰ˆæ£€æµ‹
            similar_sequences = optimized_detector.run_detection_optimized(
                save_to_file=not args.no_save,
                show_max_results=30,
                show_progress=True
            )

            result_count = len(similar_sequences)
            result_type = f"ç›¸ä¼¼åº¦â‰¥{similarity_threshold:.2f}"

        else:
            # ä½¿ç”¨æ ‡å‡†ç‰ˆæ£€æµ‹å™¨
            print(f"\nğŸ” ä½¿ç”¨æ ‡å‡†ç‰ˆæ£€æµ‹å™¨...")
            detector = DuplicateDetector(args.pdf1, args.pdf2, args.similarity)

            # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
            if not args.no_save:
                if args.output:
                    output_file = args.output
                else:
                    if args.exact:
                        output_file = get_output_filename(args.pdf1, args.pdf2).replace("duplicate_", "exact_match_")
                    else:
                        output_file = get_output_filename(args.pdf1, args.pdf2).replace("duplicate_", f"similarity_{args.similarity:.2f}_")

                # ä¿®æ”¹æ£€æµ‹å™¨çš„ä¿å­˜æ–¹æ³•
                original_save_method = detector.similarity_detector.save_results
                def save_with_custom_filename(similar_sequences, filename=output_file):
                    original_save_method(similar_sequences, filename)
                detector.similarity_detector.save_results = save_with_custom_filename

            # è¿è¡Œæ£€æµ‹
            if args.exact:
                print(f"\nå¼€å§‹æ£€æµ‹å®Œå…¨ç›¸åŒçš„8å­—åºåˆ—...")
                repeated_sequences = detector.run_detection(save_to_file=not args.no_save)
                result_count = len(repeated_sequences)
                result_type = "å®Œå…¨ç›¸åŒ"
            else:
                print(f"\nå¼€å§‹æ£€æµ‹ç›¸ä¼¼8å­—åºåˆ—...")
                print("âš ï¸  æ ‡å‡†æ¨¡å¼å¯èƒ½è¾ƒæ…¢ï¼Œå»ºè®®ä½¿ç”¨ --fast é€‰é¡¹")
                similar_sequences = detector.run_similarity_detection(save_to_file=not args.no_save)
                result_count = len(similar_sequences)
                result_type = f"ç›¸ä¼¼åº¦â‰¥{args.similarity:.2f}"

        # æ˜¾ç¤ºç®€è¦ç»“æœ
        print("\n" + "=" * 80)
        print("æ£€æµ‹å®Œæˆ!")
        print(f"æ‰¾åˆ° {result_count} ä¸ª{result_type}çš„{args.sequence_length}å­—åºåˆ—")

        if not args.no_save:
            print(f"è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

        if args.fast or args.ultra_fast:
            print("ğŸ‰ ä¼˜åŒ–æ¨¡å¼æˆåŠŸåŠ é€Ÿæ£€æµ‹!")
        else:
            print("ğŸ’¡ æç¤ºï¼šä¸‹æ¬¡å¯ä»¥å°è¯• --fast é€‰é¡¹ä»¥è·å¾—æ›´å¿«çš„é€Ÿåº¦")

        print("=" * 80)

    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­æ£€æµ‹è¿‡ç¨‹")
        sys.exit(1)
    except Exception as e:
        print(f"\næ£€æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        sys.exit(1)


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦å®‰è£…"""
    required_packages = ['pdfplumber']
    missing_packages = []

    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)

    if missing_packages:
        print("é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…:")
        for package in missing_packages:
            print(f"  - {package}")
        print("\nè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print(f"pip install {' '.join(missing_packages)}")
        sys.exit(1)


if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    check_dependencies()

    # è¿è¡Œä¸»ç¨‹åº
    main()